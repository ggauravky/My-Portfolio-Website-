{
  "posts": [
    {
      "id": 1,
      "title": "The AI on Your Desk Might Be Working for a Cybercriminal",
      "excerpt": "74% of companies face AI-powered threats in 2025. Learn how these attacks work and simple steps to protect yourself.",
      "content": "The AI on your desk might be working for a cybercriminal without your knowledge. 74% of companies face AI-powered threats in 2025.\n\nIn 2024 a global engineering firm (Arup) lost $25 million after an AI-generated deepfake convinced a CFO to transfer funds. This shows how realistic and dangerous these attacks are.\n\nAI-powered threats include highly convincing phishing messages, prompt injection attacks, and model poisoning. AI phishing messages are often perfectly written and personalized by scanning public profiles and company news.\n\nPrompt injection happens when an attacker hides malicious instructions in content that an AI model executes or shares. Model poisoning occurs when training data is corrupted, reducing accuracy and causing wrong decisions.\n\nShadow AI is another problem: employees using unauthorized AI tools can introduce new risks. Breaches involving shadow AI tend to cost significantly more.\n\nHow to protect yourself:\n- Individuals: never paste sensitive data into AI tools; verify unusual requests via a second channel; use only approved tools.\n- Companies: create AI governance, monitor AI usage, train employees on AI risks, validate training data, and deploy AI-based defenses.\n\nThree quick questions before trusting AI output:\n1. Who trained this AI?\n2. What data was used?\n3. Can I verify this somewhere else?\n\nWe are in an AI arms race. Adapt now or risk becoming the next statistic. Share this if you find it useful.",
      "category": "AI & Cybersecurity",
      "date": "2025-08-10",
      "readTime": 7,
      "tags": ["ai", "cybersecurity", "deepfake", "phishing", "shadow-ai"],
      "image": "assets/art-ai-01.png"
    }
  ]
}
